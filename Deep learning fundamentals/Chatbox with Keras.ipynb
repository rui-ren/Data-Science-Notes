{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"movie_dialog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['statement', 'reply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>you're asking me out. that's so cute. what's y...</td>\n",
       "      <td>forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>no, no, it's my fault we didn't have a proper ...</td>\n",
       "      <td>cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gosh, if only we could find kat a boyfriend...</td>\n",
       "      <td>let me see what i can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>c'esc ma tete. this is my head</td>\n",
       "      <td>right. see? you're ready for the quiz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>how is our little find the wench a date plan p...</td>\n",
       "      <td>well, there's someone i think might be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  \\\n",
       "0  you're asking me out. that's so cute. what's y...   \n",
       "1  no, no, it's my fault we didn't have a proper ...   \n",
       "2     gosh, if only we could find kat a boyfriend...   \n",
       "3                     c'esc ma tete. this is my head   \n",
       "4  how is our little find the wench a date plan p...   \n",
       "\n",
       "                                     reply  \n",
       "0                               forget it.  \n",
       "1                                 cameron.  \n",
       "2                let me see what i can do.  \n",
       "3   right. see? you're ready for the quiz.  \n",
       "4  well, there's someone i think might be   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts, target_texts = [], []\n",
    "# use set to hold the seen characters in the input and target text\n",
    "input_vocabulary = set()\n",
    "\n",
    "output_vocabulary = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '\\t' # start token SOS --> start of sequence\n",
    "stop_token = '\\n' # end token EOS --> end of sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the maximum training number is 25000\n",
    "max_training_samples = min(25000, len(df) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text, target_text in zip(df.statement, df.reply):\n",
    "    if type(target_text) == float or type(input_text) == float:\n",
    "        continue\n",
    "    target_text = start_token + target_text + stop_token\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_vocabulary:\n",
    "            input_vocabulary.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in output_vocabulary:\n",
    "            output_vocabulary.add(char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Building your character dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert each character of the input and target texts into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\ttons\\\\n'\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(target_texts[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocabulary = sorted(input_vocabulary)\n",
    "output_vocabulary = sorted(output_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(input_vocabulary)\n",
    "output_vocab_size = len(output_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input index-character mapping\n",
    "input_token_index = dict([(str(char), i) for i, char in enumerate(input_vocabulary)])\n",
    "# generate the output index-character mapping\n",
    "target_token_index = dict([(str(char), i) for i, char in enumerate(input_vocabulary)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, str(char)) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, str(char)) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one-hot vectors that represent each character\n",
    "encoder_input_data = np.zeros((len(input_texts), \n",
    "                               max_encoder_seq_length,\n",
    "                               input_vocab_size),\n",
    "                               dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts),\n",
    "                               max_decoder_seq_length,\n",
    "                               output_vocab_size),\n",
    "                               dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts),\n",
    "                                max_decoder_seq_length,\n",
    "                                output_vocab_size),\n",
    "                                dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):        \n",
    "        if char == '\\t' or char == '\\n':\n",
    "            char = ' '\n",
    "            \n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t-1, target_token_index[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57823 samples, validate on 6425 samples\n",
      "Epoch 1/100\n",
      "57823/57823 [==============================] - 145s 3ms/step - loss: 0.7413 - acc: 0.5910 - val_loss: 0.6386 - val_acc: 0.7583\n",
      "Epoch 2/100\n",
      "57823/57823 [==============================] - 146s 3ms/step - loss: 0.5804 - acc: 0.2402 - val_loss: 0.5641 - val_acc: 0.1909\n",
      "Epoch 3/100\n",
      "57823/57823 [==============================] - 135s 2ms/step - loss: 0.5294 - acc: 0.1979 - val_loss: 0.5300 - val_acc: 0.2006\n",
      "Epoch 4/100\n",
      "46464/57823 [=======================>......] - ETA: 25s - loss: 0.5045 - acc: 0.2050"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "num_neurons = 256\n",
    "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
    "encoder = LSTM(num_neurons, return_state=True)\n",
    "# \n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder states\n",
    "encoder_states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(None, output_vocab_size))\n",
    "decoder_lstm = LSTM(num_neurons, return_sequences=True,\n",
    "                    return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data],\n",
    "          decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "thought_input = [\n",
    "    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))\n",
    "]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=thought_input)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_ouputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
